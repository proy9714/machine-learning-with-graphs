{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca0a1ed",
   "metadata": {},
   "source": [
    "# Node Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7b6d9",
   "metadata": {},
   "source": [
    "## Graph Representation Learning\n",
    "\n",
    "Answer briefly:\n",
    "\n",
    "1. How does graph representation learning alleviate the need to do feature engineering every single time?\n",
    "\n",
    "1. Why do we map nodes to vectors instead of using the raw graph structure (e.g., the adjacency matrix)?\n",
    "\n",
    "1. What happens after we get the node embeddings, how do we use them? (Hint: Think of a node classification task, where we want to assign labels to each node.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a70150",
   "metadata": {},
   "source": [
    "## Inferring Graph Structure from Node Embeddings\n",
    "\n",
    "Consider the following 2D embeddings of nodes A, B, C and D.\n",
    "\n",
    "<center>\n",
    "\n",
    "| Node | $z_1$ | $z_2$ |\n",
    "|------|-------|-------|\n",
    "| A    | 0.8   | 0.6   |\n",
    "| B    | 0.7   | 0.5   |\n",
    "| C    | -0.6  | 0.7   |\n",
    "| D    | 0.9   | 0.5   |\n",
    "\n",
    "</center>\n",
    "\n",
    "1. Compute the pairwise similarities between nodes using dot product.\n",
    "\n",
    "1. Based on the similarity values, which edges are most likely to exist in the original graph? Which pairs are unlikely to be connected?\n",
    "\n",
    "1. Draw a possible graph consistent with these embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09aaea",
   "metadata": {},
   "source": [
    "## Random Walk Similarity\n",
    "\n",
    "To optimize node embeddings for random walk similarity, we minimize the following loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{u \\in V} \\sum_{v \\in N_R(u)} -\\log{\\left(\\frac{\\exp{(z_u^T z_v)}}{\\sum_{n \\in V} \\exp{(z_u^T z_n)}}\\right)}\n",
    "$$\n",
    "\n",
    "1. Why minimizing this loss naively is too expensive, what's the culprit term?\n",
    "\n",
    "1. How do we solve this issue?\n",
    "\n",
    "1. Consider the following 2D node embeddings for nodes $u$, $v$, $n_1$ and $n_2$.\n",
    "\n",
    "    <center>\n",
    "\n",
    "    | Node  | $z_1$ | $z_2$ |\n",
    "    | ----  | ----- | ----- |\n",
    "    | $u$   | 0.0   | 0.0   |\n",
    "    | $v$   | 0.0   | 1.0   |\n",
    "    | $n_1$ | -1.0  | 0.0   |\n",
    "    | $n_2$ | 1.0   | 0.0   |\n",
    "\n",
    "    </center>\n",
    "\n",
    "    Given the following, run one step of Stochastic Gradient Descent (SGD). What's the resulting embedding for the node $u$?\n",
    "\n",
    "    - Node $u$ is the target node.\n",
    "    - Node $v$ is a positive context of $u$ (appears in the same random walk).\n",
    "    - Nodes $n_1$ and $n_2$ are other nodes in the graph.\n",
    "    - Learning rate $\\eta=0.1$\n",
    "    <!-- - Assume the softmax probabilities (for simplicity) are: $P(v|u)=0.6$, $P(n_1|u)=0.25$, $P(n_2|u)=0.15$ -->\n",
    "\n",
    "    Hint 1 (SGD update): $z_u \\gets z_u - \\eta \\frac{\\partial \\ell(u,v)}{\\partial z_u}$\n",
    "\n",
    "    Hint 2 (Gradient): $\\frac{\\partial \\ell(u,v)}{\\partial z_u} = - z_v + \\sum_{n \\in V} P(n|u)\\, z_n$\n",
    "\n",
    "    Hint 3 (Softmax): $P(n|u) = \\frac{\\exp(z_u^\\top z_n)}{\\sum_{m \\in V} \\exp(z_u^\\top z_m)}$\n",
    "\n",
    "1. How did the embedding of node $u$ change after the SGD update? Explain how the direction of movement relates to node similarities.\n",
    "\n",
    "1. What would happen if:\n",
    "    - we remove the culprit term in $\\mathcal{L}$ or have no negative samples at all?\n",
    "    - we collect many extremely long random walks? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23d8ff",
   "metadata": {},
   "source": [
    "## Programming: Random Walks on the Karate Club Network\n",
    "\n",
    "In this exercise you'll implement and analyze biased random walks on a small network (Zachary's Karate Club) to explore how the walk parameters affect the paths and local/global structure captured by the walks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd473309",
   "metadata": {
    "tags": [
     "code_fig_gen_question"
    ]
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the karate club graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(\n",
    "    G,\n",
    "    with_labels=True,\n",
    "    node_color=\"lightblue\",\n",
    "    font_size=9,\n",
    "    node_size=150,\n",
    "    pos=pos,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.annotate(\n",
    "    \"Karate Club Network\",\n",
    "    xy=(0.5, 1.05),\n",
    "    xycoords=\"axes fraction\",\n",
    "    ha=\"center\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax.margins(0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6a1b4",
   "metadata": {},
   "source": [
    "1. Complete the following `biased_random_walk` function, which performs a single biased random walk with a given length, start node, $p$ and $q$ parameters.\n",
    "\n",
    "    Hints for implementation:\n",
    "\n",
    "    - Start at `start_node`.\n",
    "    - At each step, consider neighbors of the current node.\n",
    "    - Assign probabilities to neighbors according to:\n",
    "        - Return: neighbor = previous node → weight $\\propto$ $1/p$\n",
    "        - In-out: neighbor connected to previous node → weight $\\propto$ $1$\n",
    "        - Neighbor further away from previous node → weight $\\propto$ $1/q$\n",
    "    - Normalize probabilities and randomly choose the next node.\n",
    "\n",
    "    This is essentially the biased random walk from `node2vec`. For more description, you can refer to the paper [here](https://arxiv.org/pdf/1607.00653)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2503f4",
   "metadata": {
    "tags": [
     "q_code"
    ]
   },
   "outputs": [],
   "source": [
    "def biased_random_walk(G, start_node, walk_length, p=1, q=1):\n",
    "    \"\"\"\n",
    "    Perform a single biased random walk of length 'walk_length' starting at 'start_node'.\n",
    "\n",
    "    Parameters:\n",
    "    - G: NetworkX graph\n",
    "    - start_node: node to start the walk from\n",
    "    - walk_length: length of the walk\n",
    "    - p: return parameter (likelihood of immediately revisiting a node in the walk)\n",
    "    - q: in-out parameter (bias towards DFS vs BFS)\n",
    "\n",
    "    Returns:\n",
    "    - walk: list of node IDs in the walk\n",
    "    \"\"\"\n",
    "\n",
    "    walk = [start_node]\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    for _ in range(walk_length - 1):\n",
    "\n",
    "        # Pick the last node in the current walk\n",
    "        cur = walk[-1]\n",
    "        \n",
    "        # Find all the neighbors of the current node\n",
    "        neighbors = list(G.neighbors(cur))\n",
    "\n",
    "        # If the are no neighbors, break the walk\n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "\n",
    "        # compute weights alpha_pq based on previous node, p, q\n",
    "        # walk[-2] is the previous node from which we came to 'cur'\n",
    "        prev = walk[-2] if len(walk) > 1 else None\n",
    "\n",
    "        # For simplicity, uniform probabilities if no prev\n",
    "        if prev is None:\n",
    "            probs = [1 / len(neighbors)] * len(neighbors)\n",
    "        else:\n",
    "            probs = []\n",
    "            for nbr in neighbors:\n",
    "                # Exactly same as previous node\n",
    "                if nbr == prev:\n",
    "                    weight = 1 / p\n",
    "                # If nbr node has edge between current node as well as previous node\n",
    "                elif G.has_edge(nbr, prev):\n",
    "                    weight = 1\n",
    "                else:\n",
    "                    weight = 1 / q\n",
    "                probs.append(weight)\n",
    "            # normalize\n",
    "            s = sum(probs)\n",
    "            probs = [w / s for w in probs]\n",
    "        \n",
    "        # choose next node\n",
    "        import random\n",
    "\n",
    "        next_node = random.choices(neighbors, weights=probs, k=1)[0]\n",
    "        walk.append(next_node)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227665e2",
   "metadata": {},
   "source": [
    "2. Using your `biased_random_walk` function, generate 10 walks starting from node 20 for each of the following cases:\n",
    "    - Unbiased: $p=1$ and $q=1$\n",
    "    - BFS: $p=1$ and $q=2$\n",
    "    - DFS: $p=1$ and $q=0.5$\n",
    "\n",
    "    Then, compute the average distance from starting node for each case using the given `average_distance_from_start` function. Do the average distances align with the unbiased/BFS/DFS descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf147f",
   "metadata": {
    "tags": [
     "q_code"
    ]
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "def average_distance_from_start(G, walks):\n",
    "    \"\"\"\n",
    "    Computes average shortest-path distance from the starting node\n",
    "    for each walk, then averages over all walks.\n",
    "    \"\"\"\n",
    "    distances = []\n",
    "    for walk in walks:\n",
    "        start = walk[0]\n",
    "        for node in walk[1:]:\n",
    "            dist = nx.shortest_path_length(G, source=start, target=node)\n",
    "            distances.append(dist)\n",
    "    if len(distances) == 0:\n",
    "        return 0\n",
    "    return sum(distances) / len(distances)\n",
    "\n",
    "\n",
    "# load the karate club graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "avg_dist_unbiased = 0\n",
    "avg_dist_bfs = 0\n",
    "avg_dist_dfs = 0\n",
    "\n",
    "############# Your code here ############\n",
    "\n",
    "walks_unbiased = [biased_random_walk(G, start_node=20, walk_length=10, p=1, q=1) for _ in range(10)] \n",
    "# print(f\"Unbiased walks from node 20: {walks_unbiased}\")\n",
    "\n",
    "walks_bfs = [biased_random_walk(G, start_node=20, walk_length=10, p=1, q=2) for _ in range(10)]\n",
    "# print(f\"BFS-biased walks from node 20: {walks_bfs}\")\n",
    "\n",
    "walks_dfs = [biased_random_walk(G, start_node=20, walk_length=10, p=1, q=0.5) for _ in range(10)]\n",
    "# print(f\"DFS-biased walks from node 20: {walks_dfs}\")\n",
    "\n",
    "avg_dist_unbiased = average_distance_from_start(G, walks_unbiased)\n",
    "avg_dist_bfs = average_distance_from_start(G, walks_bfs)\n",
    "avg_dist_dfs = average_distance_from_start(G, walks_dfs)\n",
    "\n",
    "#########################################\n",
    "\n",
    "print(f\"Average distance from start (Unbiased): {avg_dist_unbiased}\")\n",
    "print(f\"Average distance from start (BFS): {avg_dist_bfs}\")\n",
    "print(f\"Average distance from start (DFS): {avg_dist_dfs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbb8e6",
   "metadata": {},
   "source": [
    "## Programming: Node Embeddings via node2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e53c1b",
   "metadata": {},
   "source": [
    "In this exercise, you'll use the tools from `PyG` to obtain embeddings for nodes in the Karate Club Network with `node2vec` algorithm. Then, you'll visualize the embeddings in a 2D space.\n",
    "\n",
    "1. First, complete the `train` function in the following code snippet. The part you need to implement computes the loss using `Node2Vec` class implemented in `PyG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60d5893",
   "metadata": {
    "tags": [
     "q_code"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_scatter\\_scatter_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_cluster\\_grid_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_sparse\\_convert_cuda.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'Node2Vec' requires either the 'pyg-lib' or 'torch-cluster' package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m edges = edges + [(v, u) \u001b[38;5;28;01mfor\u001b[39;00m (u, v) \u001b[38;5;129;01min\u001b[39;00m edges]  \u001b[38;5;66;03m# make undirected\u001b[39;00m\n\u001b[32m     14\u001b[39m edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m model = \u001b[43mNode2Vec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwalks_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_negative_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m.to(device)\n\u001b[32m     27\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=\u001b[32m0.05\u001b[39m)\n\u001b[32m     28\u001b[39m loader = model.loader(batch_size=\u001b[32m64\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Priyadarshi\\.conda\\envs\\mlwg\\Lib\\site-packages\\torch_geometric\\nn\\models\\node2vec.py:67\u001b[39m, in \u001b[36mNode2Vec.__init__\u001b[39m\u001b[34m(self, edge_index, embedding_dim, walk_length, context_size, walks_per_node, p, q, num_negative_samples, num_nodes, sparse)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p == \u001b[32m1.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q == \u001b[32m1.0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     68\u001b[39m                           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrequires either the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyg-lib\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m                           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch-cluster\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     71\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m                           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrequires the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch-cluster\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: 'Node2Vec' requires either the 'pyg-lib' or 'torch-cluster' package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import Node2Vec\n",
    "import networkx as nx\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# load the karate club graph\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# convert networkx graph to edge index tensor\n",
    "edges = list(G.edges())\n",
    "edges = edges + [(v, u) for (u, v) in edges]  # make undirected\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "model = Node2Vec(\n",
    "    edge_index=edge_index,\n",
    "    embedding_dim=8,\n",
    "    walks_per_node=10,\n",
    "    walk_length=5,\n",
    "    context_size=3,\n",
    "    p=1.0,\n",
    "    q=1.0,\n",
    "    num_negative_samples=5,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "loader = model.loader(batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ############# Your code here ############\n",
    "\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f2bbc",
   "metadata": {},
   "source": [
    "2. Now, let's plot the learned embeddings in a 2D space using Principal Component Analysis (PCA). Notice the node colors are determined by the community that the member is a part of. The following text from [Wikipedia](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) explains the communities. \n",
    "\n",
    "    > The network captures 34 members of a karate club, documenting links between pairs of members who interacted outside the club. During the study a conflict arose between the administrator \"John A\" and instructor \"Mr. Hi\" (pseudonyms), which led to the split of the club into two. Half of the members formed a new club around Mr. Hi; members from the other part found a new instructor or gave up karate. Based on collected data Zachary correctly assigned all but one member of the club to the groups they actually joined after the split.\n",
    "\n",
    "    Finally, use the following code to plot the embeddings learned by your model, and interpret the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1faf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# get embeddings\n",
    "z = model().detach().cpu().numpy()\n",
    "\n",
    "# reduce to 2D for visualization\n",
    "z_2d = PCA(n_components=2).fit_transform(z)\n",
    "\n",
    "# colors are based on club membership\n",
    "colors = [0 if G.nodes[i][\"club\"] == \"Mr. Hi\" else 1 for i in G.nodes()]\n",
    "\n",
    "# plot nodes\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "scatter = ax.scatter(\n",
    "    z_2d[:, 0], z_2d[:, 1], c=colors, cmap=\"coolwarm\", s=200, edgecolors=\"white\"\n",
    ")\n",
    "\n",
    "# add node labels\n",
    "for i, (x, y) in enumerate(z_2d):\n",
    "    ax.text(\n",
    "        x + 0.00,\n",
    "        y + 0.00,\n",
    "        str(i),\n",
    "        fontsize=8,\n",
    "        color=\"lightgray\",\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "\n",
    "# add edges from the original graph\n",
    "for edge in G.edges():\n",
    "    x0, y0 = z_2d[edge[0]]\n",
    "    x1, y1 = z_2d[edge[1]]\n",
    "    ax.plot([x0, x1], [y0, y1], color=\"gray\", alpha=0.5, linewidth=0.5, zorder=0)\n",
    "\n",
    "# add legend\n",
    "handles, labels = scatter.legend_elements()\n",
    "ax.legend(handles, [\"Club 0\", \"Club 1\"], title=\"Community\", loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4019b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlwg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
